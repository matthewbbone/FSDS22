{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f94b4d7-69b5-442b-a9e6-c6653fcb5aa3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fundamentals of Social Data Science \n",
    "\n",
    "Week 1. Day 3. Exercises from Chapter 3 of FSStDS \n",
    "\n",
    "Within your study pod discuss the following questions. Please submit an individual assignment by 12:30pm Monday, October 17, 2022 on Canvas. \n",
    "\n",
    "These assignments have two sets of questions. The top questions have answers already in them. The last question is for you to submit. That last question will be given written feedback via the teaching assistants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bdf5e73-8712-42c6-b7a5-ec3040265e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# RUN THIS CELL IF YOU HAVE THE KEY \n",
    "# This is what we use to create the sample answers as encrypted text\n",
    "\n",
    "import pandas as pd \n",
    "import cryptography\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def encrypt(message: str, key: bytes) -> bytes:\n",
    "    return Fernet(key).encrypt(message.encode())\n",
    "\n",
    "def decrypt(token: bytes, key: bytes) -> str:\n",
    "    if not key: \n",
    "        return \"Hey now, why not try these on your own first?\"\n",
    "    return Fernet(key).decrypt(token).decode()\n",
    "\n",
    "# In case you're stuck or want to check your work, \n",
    "# uncomment the key and then run the sample answer cells. \n",
    "\n",
    "key = None\n",
    "\n",
    "# key = b'_beepbeepbeepbeep1234567890beepbeepbeepbeep=' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99d8ef-0f7f-451e-ac04-a63420375604",
   "metadata": {},
   "source": [
    "# Shorter questions with answers\n",
    "\n",
    "These questions use a pre-chewed IMDB file of movies with over 10k votes on the platform. It's considerably smaller than the 760mb file of all movies. It should be available from Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcf4aa-da92-4dca-9d3b-7e68a9e5bf82",
   "metadata": {},
   "source": [
    "## Step 1. Read in the file. \n",
    "\n",
    "The first thing is to read in the file, `\"imdb_over10k_votes_movies.csv\"`. This is a list of movies from IMDB that have more than 10,000 votes on their ratings. I have prepared this data from a data export freely available from IMDB. The code for how I did it is in the appendix to this formative. \n",
    "\n",
    "There's conicidentally also about 10k movies in this data set. A big number but not too unwieldy for a personal computer. Herein, we are just going to practice asking and answering questions about this data. Most of what we are going to do with these questions is rank, summarise, and compare. We might want to compare the runtimes of movies of different genres or ratings.\n",
    "\n",
    "To get you started, check that your DataFrame looks similar to the one here from this code. For the example answer I stored the file in an adjacent folder called `data`, so for me that is why the path looks like so. I similarly recommend you having a separate folder for your data just in a sibling folder to this one (rather than a 'subfolder' within this one). As in: \n",
    "\n",
    "~~~\n",
    "- FSDS\n",
    "  - Data\n",
    "    - imdb_over10k_votes_movies.csv\n",
    "  - Formatives\n",
    "    - SURNAME_INIT_WD21_w1formative_DataFramePratice.ipynb\n",
    "  - Summative \n",
    "  - Readings\n",
    "  etc...\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b059cac4-af19-4fa8-a6d4-befe9913965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9694 entries, 0 to 9693\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   tconst          9694 non-null   object \n",
      " 1   primaryTitle    9694 non-null   object \n",
      " 2   originalTitle   9694 non-null   object \n",
      " 3   startYear       9694 non-null   int64  \n",
      " 4   runtimeMinutes  9694 non-null   int64  \n",
      " 5   averageRating   9694 non-null   float64\n",
      " 6   numVotes        9694 non-null   int64  \n",
      " 7   genre1          9694 non-null   object \n",
      " 8   genre2          8840 non-null   object \n",
      " 9   genre3          6361 non-null   object \n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 757.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 1 answer below (ensuring your file is in the right folder)\n",
    "from pathlib import Path\n",
    "\n",
    "movie_df = pd.read_csv(\"../data/imdb_over10k_votes_movies.csv\")\n",
    "\n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4815292c-05ef-426f-884b-bec049594c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey now, why not try these on your own first?\n"
     ]
    }
   ],
   "source": [
    "ans = b'gAAAAABh6UcLaoFySY7xkY_0mmZk5vkcNgqUdZpLg1CW04bMW3E-pKGS2js4S19wn5ja0Z3jrkpzf6siH_x_5C0oj_rFHAuRnNXk_zyGKTtmkube7-Ha6uO9LEt3T6cHMPu4wXSmF1oLp5bja_HeQw5Xs0IDyTW5D3ZW_9acMPEOEPjOZ7-XrsKWXLkAdZLBxIY-c2JyfGX8fv7FRwkMEFz1H4hGKOhip77mFH_vMEhxCtChIE7EoSN5NqV9BaSm9gl4nYjNjvRLI93Q3aOV0sRVXXBlDE7GE6vcgvDmZL5wJLHTn1pJN6ZycN6iU5F10Sef6SwW9l1AO26U95O02b_U-hFaiLnMEw04_0VCay0ZG0Feuc9NuQVn9cs0B43am5XuIM9kAdlAOXUmmLw9YE-f8VB5877l1rnhBddp10yPtgFBr0pGYFfpzj_tZj48190xKLEd2R1CV5mngQqx557MDZ_9XSFCq3JG-IoEQqdkc_1nHEhkqS0NzfapMGgkQh1vMnIn4opLy-51iBp3SpRi0VsfPke_3PgvAoO6T-Ntrowf-nZtW-W2s8TJQ8pj6-OCTw3ti74TFyguenw2WbPCf-HzcnnabHbFa7NYkDcXoJSN7Dnxri9slpAp6iIk3hyAqWPhDZjyPv90eCjivKuCL63Y-mhEFEKhSziHm4cMpWF2fxyYJs3y69buaQqefNFTV9VMFeO9Dj-qTA1YUCFh5AU0R5eTOkWq7-hB6yh3Qmvy6ZbbU93gcEHc-nd8nLsTCvftODXZKgqkj5NjYrSK9VjtVSc3tGQ2w8b4mAre_ahQtq54fY1yFj6GF_5KByc6cOqiWwqKpNp6GifV6Z6KT0FVj6GujflT4JDry1a8JbmtrD6-wp7ONPQ2cJlQE5HL_wxcmyiY5nDkiXGQO27-obhsJaz5gDNFMfrZFZ18kHnwqFroZaj6ZvFVxLdnH-OddoNvUDg5_lr6XvEZj1z0FHSjPRI1mWL-5BeEbGyGqQAkoCN-vJYcx8KUiLwHaKtKhMwA99HoLgL-Avqi6jHWICdm96Ye0TVav55E0T_m5SFcWwr4huM='\n",
    "\n",
    "print(decrypt(ans, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad1901-1a63-4851-9c3e-2e5f326be980",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2. Learn about the data set. \n",
    "\n",
    "Below are some questions to ask about the data set. I have printed some answers. Your job is to fill in the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73506cdc-24b7-428d-8521-a2d591ae199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this data set are 9694 in total.\n",
      "The movie with the lowest rating is Ellipsis with a rating of Ellipsis.\n",
      "The movie with the highest rating is Ellipsis with a rating of Ellipsis.\n"
     ]
    }
   ],
   "source": [
    "num_movies = len(movie_df)\n",
    "lowest_rating = ...\n",
    "lowest_rating_name = ... \n",
    "highest_rating = ...\n",
    "highest_rating_name = ... \n",
    "\n",
    "print(f\"In this data set are {num_movies} in total.\") \n",
    "print(f\"The movie with the lowest rating is {lowest_rating_name} with a rating of {lowest_rating}.\")\n",
    "print(f\"The movie with the highest rating is {highest_rating_name} with a rating of {highest_rating}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d6997ae-cf16-43bb-8266-df33021b78b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey now, why not try these on your own first?\n"
     ]
    }
   ],
   "source": [
    "ans = b'gAAAAABh6Uhn5K1CBvVi-kmnwLUj1bwYTgtNsO7BgdRlHigpsRPj3R60acHEg7b8HAPtidj6UY5j39MAPoXf24MkbtzLj--_RPj4KrNSWWODKIG4_KwmRUap3_u17SxklPscaOUOQkl_1NNjAZ4uh8nNe1u5Jbrgo6KtyUV54BNjrhkTx6rwi-1K-VbzL17TSEkARKI8z42xmZBVTl5rkPA_P6PdOy_pFisZjcYfplFVvHOe4A25xg_nGguMVtvC_4b9gOJzVZ-LGvwASUS115rokK3H4LtZtyjJUQyUuRpgfMfMaX-EhuUHxbBEvmovcdDePRRp_qUWH7_B7pYQ3wI6Y54vnEPZ6WyVC5x4KDpU7QtyozW_ziv0VT9fApTcfsn2BWEXMuUsDAChbXXxgDVv-Q02Jh12S9gLgJJsd-58jBar-wePIoGe5__5Dhx8OGPno1ACM-NTbmyj99C6Np8M-QLZVC2vnqgk0kQTNfIC992vq17FxUdWJvfxVnLVaxwsQxYaGnZ-54fCTo5EXoOCgBiOstanvdIIgWK2XRLBKQSYzb8QGTR4S04h3J2sdXkgs7AS_2Xkso9-HHlqdKBwhfz24rgFKR82Kl14IQq-lTXbwElIHCR5h6GY5x0V1YCyZoubsBPzYaGNPOig3wk7u4zpzGehs2EL94cLHz5XvDA-kSdWFfwoRmwipH5zuj0axp3QqSs2eXYZHy_v6QDvF5BXSWqv2MqkHxepG0cQtBVD5v7f95tgTQ8GOSwqyIomo-YfQog2LLAIMw5qrSaM7_WG67Z2cf5fjDWrSNGv6uxHQK9wwTcZUV-7w-vhUqOYy94X17K_cBO89Fut51qH_mDypu54OBYaQGZ_3s4pQW0wfzROMEnpeBoFu5IUcKCQPd9hQkiCSbt3rKyBtUPCRYZXhvGQcajqli2NsR35r3ojN3BWgwZgeZPHP-MOuROd_tB_BvqR-oyUpwOsRc9GvjHBR-wd1qiTics8WU2NREyZedaK5pjXc7bdxKrTfmfXrjCp1HT7KplHgjrT0d8tp8Kei3aflmT9f2akGTpJf7vJpw_l7qbPgWP9Eexx-oKHpsC0JX43nXG0vXgjYvLz8NhULeivxo4GfAIXOe-Q-AIgtcIEV8k7Q7l49_bdH55zwIPz2xd9u36iMsdXHG2POJYC1lO0YuYRWFe7SGihONGvMnsk-Ay4DlkD844RXNkzWIpg2ngW6MwYkvi64ecIn37l_3MuUOQP-x1eBfYezcTYLG7VBkkEXiRXO9ML0F7hulfRoyhwqUqdbNoDXDTovE0j9yRr5rfxCAQIYnmOquHml3fBf15zY4MWkjI7Mozwy_kQCYoJ9orOj6mvSqU8_eXwz83EbFMhtOkkOriBiwteaE_Dqh4WcCHq_07rihNs525oQJmSpENL2NnCrYXX-8Z3gI7dR94bgOHhzHVWf6sOISzbpLY5gZM-yF1tePs-Inta3aoc7GVjkzqZiNMVT4AkV4L9cx9ClSwzKGlpXOavax2h8nK9EijGOZ9KrIyyfrNSnMNVffRZwLdyyL6GhHClwCALVoerPzUF2D1SEnxDN2s1RwtiBSIF1YfI9xKYRXou1KOkxdILQyJH4vKzR7EL9VBVZUSg3zHkUTfiY6PQRMYKdkadUw9sbA21kqwG5p6XOEWzrfCdFeHv-Gh4ifshttoFL20_9FX3PxCpzz7iRPa5aL39t5YWhOp-t2nWeQx1Wf1SyGeA7LU3K4gdVAyzlR4zonHuAuotouLcFdE4n_Ew9aW6Y84cZTyAHS1TNXVbvEpirO_ywVGFGjJeBa-0O_mIhJBXuLph6WLFx5RMfdjDDnQ='\n",
    "\n",
    "print(decrypt(ans, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc9d12-79c0-4a1c-a33e-136aa78fed6e",
   "metadata": {},
   "source": [
    "## Step 3. Compare some groups \n",
    "\n",
    "### First comparison - some arbitrary cut points. \n",
    "Let's create some groups and look at the scores within these groups. This is a comparison of means (which is a pre-cursor to a `t-test` which asks \"these means have different numbers, but are they _significantly_ different\". You do not have to do a t-test here, just report the mean differences. \n",
    "\n",
    "We are using somewhat arbitrary cut-points. Cut the data to all movies with a rating of 8 or more to all movies with a rating of 5 or less. \n",
    "\n",
    "Then we can ask, do higher rated movies have a shorter or longer runtime than lower rated movies? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20381282-5cc4-417a-a5fc-58f52e609acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this data set are Ellipsis movies with an average score of 8 or more.\n",
      "These movies have an average runtime of 0.00 minutes.\n",
      "In this data set are Ellipsis movies with an average score of 5 or less.\n",
      "These movies have an average runtime of 0.00 minutes.\n"
     ]
    }
   ],
   "source": [
    "num_above8 = ...\n",
    "avg_above8 = 0\n",
    "\n",
    "num_below5 = ...\n",
    "avg_below5 = 0\n",
    "\n",
    "\n",
    "print(f\"In this data set are {num_above8} movies with an average score of 8 or more.\")\n",
    "\n",
    "print(f\"These movies have an average runtime of {avg_above8:0.2f} minutes.\")\n",
    "\n",
    "print(f\"In this data set are {num_below5} movies with an average score of 5 or less.\")\n",
    "\n",
    "print(f\"These movies have an average runtime of {avg_below5:0.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76493106-ca43-4f1a-94d6-288eaffcd0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey now, why not try these on your own first?\n"
     ]
    }
   ],
   "source": [
    "ans = b'gAAAAABh6UkhBWikSoloTo-xjoGch1v1aWxtbsvOB5h1F594T_Z0_y346UE66HJGm819Qu9K8HoelHN5y7drCw1F5I--WRaxQdkkKSZSBMwNDI_EzaNYlMX-7yIdJKR-noLjNs8kgRXSQ4Vp6a38X1gXwdoDMqpCLlKu8gA6o1pRDjptbBDp8CNiloK93RKCZrMKkfh1O7Pp640SRWCKAZ0UY8oIRmpr77sdh9n9fxULf_g-8nCUswqO1qGJytHITSmT1UODQP76Op7NOqTEViguuweELUd5Zzv8KPvwvGaMwi1dKoPzGrvfMaUkKrd6v6CQ7iMwkijL4gXkndFaC7_3nV3dDEEUsnf41pN6CEiqOZnMu1srpwW_OWbmVnwwD5MGR9f_fxJHXVXrJHo8D-m4SJSjgyHrSbzLn_1mY4m1PPrOnfnjpyEAHBWVgttK-t7qRlhwjYW7b_9hvtITVk9zv9_ga18UUYtEscl0ep0Hy-u0fejkraZfgt1aYX7khDldH-wEH4RH3hac-Zq2TLxKLJg7udp0g1Dj_522LR9qUVIBHkbDNwcTr-YXpm5K8WUbbYvh3Z6w3lWjJdYD1tvO0SOUw2NSiudbK06o0qwi4sTBxmVS1dIzDgxoGlxxfdVGOtj8JfhRXXsTSZ9uJlOnHI9Nh_Kuk80Y2LQJHZu3ciYVCQ7nNiqbo8l2zhbR7rKHwyqZPKYDmAhBrsXI3YzB-g6uKqdCPyU0ApxOSCSe8uCeQxrumfo_PGHwPA2iE3KtKsjhJD6HKcjyS68EhFeQBqgKMiC7bhuw9E1PZQwabUDVuAfX3gnjXT975AT93WnkJ2xBzHL9'\n",
    "\n",
    "print(decrypt(ans,key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f5f5b-cde3-4503-943f-b5f0429973d5",
   "metadata": {},
   "source": [
    "### Second comparison - between genres\n",
    "\n",
    "The data have three genre columns. Compare the ratings of movies in the `'Comedy'` genre to those in the `'Drama'` genre. The simplest way would be to mask by `[movie_df.genre1 == 'Comedy']`. But what about the other two columns? Sometimes movies are classed as 'Comedy' and 'Western'.\n",
    "\n",
    "How might you account for those?  Here's a hint: if you have two columns to put in your comparison statement, you put them each in their own parenthesis and then use `|` as the *OR* symbol (as well as `&` for the _AND_ symbol). So we might say:\n",
    "\n",
    "~~~ python\n",
    "short_or_long = movie_df[(movie_df.runtimeMinutes < 90) | (movie_df.runtimeMinutes > 180)]\n",
    "long_and_bad = movie_df[(movie_df.runtimeMinutes > 150) & (movie_df.averageRating < 6)]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2dfbecd-6bb5-4584-9027-0a120af3a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the data set there were Ellipsis Comedy movies.\n",
      "They had an average score of 0.0.\n",
      "In the data set there were Ellipsis Drama movies.\n",
      "They had an average score of 0.0.\n"
     ]
    }
   ],
   "source": [
    "num_comedy = ...\n",
    "avg_comedy = 0\n",
    "\n",
    "num_drama = ...\n",
    "avg_drama = 0\n",
    "\n",
    "print(f\"In the data set there were {num_comedy} Comedy movies.\")\n",
    "print(f\"They had an average score of {avg_comedy:0.1f}.\")\n",
    "\n",
    "print(f\"In the data set there were {num_drama} Drama movies.\")\n",
    "print(f\"They had an average score of {avg_drama:0.1f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8b860d-a1a3-4c12-80dd-3ac81df379a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey now, why not try these on your own first?\n"
     ]
    }
   ],
   "source": [
    "ans = b'gAAAAABh6Une6ifsZylGBSvBLkJvbqYy1oMtajxVva10OsyTaXqvt3S5UwzvSCG6ei2GTS1Z2hiweFSyKG4WZna5er5hbvKIlaCsA_AU3XNsGrKINA_RnA1028vSnlobRBK1dcY3TXmwYUIE6k1a_N5v_WboCxfO8mCvVg4Y2KGTS4cIqc-Ct-adKd8W1xXsOjgFscg7ZB847FZsIZ5idqM9heQH7BOIWK3j_cyBn9Fg0zaYVJK5zrrhXDFwBU9O9AXSjRjRLmwM6tjkeIWQ2zAHpNWWd29JYD60sSPuuSvDH4sWia0cOAek13p_eMIG5EDCyg_kAAB1od2dIz2MMH5tagpAYy7hiXyEALQ0aFfkUoW9PBPSm4RhpcBLxgTYX7wDOeOoufg28z7cewS-KzyEFbC6SxueT_6S1niD0Bw1OVu94dAw-lmilIkHy3zEHZg8K-aVVpyVWGl7ypGRqpaMEJKmxHl5w_fx1itZXF7mCGsV7ExAodn_tMhnWrYOao61XU1er8MRJe4sM5alwf1NhEaRl_01BnjLlNcG4BaSIq4UxOmH1C8xqc3X8cr6obAYcjORUUMhqZhg75UCKMXL-YmG-rkBxiYePJU16QizlfoxkRxxSEk-F_qQMUTXdBa7pRl0NOFGYb3ffL78GfGOIMkFhsv_2VKsGK5jn7aKeow2QXac0kaCEtfPWuicvbSkkn-wzbWrJmIxEojQv2vWHYQc_zJ12VFvvcSi3ll0X8CWytvmFZdCeUDB6Kzg7cTi5oydjd290QuQxc5-iTf0yQFmoYQeB9rbL7RuAPij1AbIW64Pt_uY2PxtsIa3JKfDGwZrU1Whm1w4klp-ul8mb4otNmMWZJun62atQ53h01FzavbSMXqAcxs3gjqMfmHQfYutyvFAvYnpGGUUE--styNui6PvFMyq9QGaOuFBqzlRKn1dXo-B0moVpeTXM4M4yiI-wlYreeAiUrZEt3b_vnvsrtuKWlh1MHfCcHP4kOy-4AI3aSrgnYAEJdJMI_bse0f0WtRKWyYWsj9-xsBunH4G2-BCofQGfF1h2pjuxhX-9k3BfXPM3lRR8isllY_RBcwIg-Jb1FFpoNDWOQ6pG_zYiEV3fg_eo8xdWLIpx2DJ1UqjkFYOnpH6iU8JmmU9wJyjafHFPi-W6tfila1BLbD9Ddy7dr2Vb8MBXE4ItTe22nVP3ASTZ_59PYFCXdCM8g9Gbj4xmRcn-hg6DWK9i4VD3Sbe1xFih5kOmYXHh3NTpVcxxirPSLQPzBBwE7w4SHUMp1I3y1tpptsWCC6vyuPMy62TSQdhWrfigX2i5kFUBJGUQlU5m7XjNvCWcJP63wcv-LzYVNamG6JKttO-Jfo2uoPDAMaH0uaX3Kok2DfzYotk5czRVJlMBrmFZQx5FHgpP59Ouf6i6t9CS6vf8B0AxqZY9B1Bbvm_BVPqzLThLD97Uq8='\n",
    "\n",
    "\n",
    "print(decrypt(ans,key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40bc89e8-9c87-48b4-9e72-b77a16c95fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def encrypt(message: str, key: bytes) -> bytes:\n",
    "    return Fernet(key).encrypt(message.encode())\n",
    "\n",
    "def decrypt(token: bytes, key: bytes) -> str:\n",
    "    if not key: \n",
    "        return \"Please wait for the key - try these on your own!\"\n",
    "    return Fernet(key).decrypt(token).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e4b02b-d8e9-4593-9657-dec45bb97f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note these are not encrypted below\n",
    "key = b'fundamentalsofsocialdatasciencemichaelmas22_' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebde3ff-3476-4529-88cd-f838b5562a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19aaf0e-d810-4053-98a4-e878d8ae3824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216b578-1d44-4487-8823-360fe23f545f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1791cd5f-5181-4132-b5cb-3e24ea1e4ab3",
   "metadata": {},
   "source": [
    "# The long question: Build a query machine \n",
    "\n",
    "For this long question you are asked to build and submit (either here in a cell or as a separate .py file) a script that will allow someone to query a data frame using text. \n",
    "\n",
    "Below are some skeleton code to help you get going. You will notice that currently you can:\n",
    "- Enter a verb, shape, and variable which will be parsed.\n",
    "- Two verbs have been implemented: `loadcsv` which will load a csv as a DataFrame and `exit` which will exit the program. \n",
    "- Please create a means to use the verb \"get\" to return a row, a column, or a single cell.\n",
    "\n",
    "1. Please create a means to use \"set\" to set the value of a single cell \n",
    "2. Please create a means to use \"list\" to display either the columns, number of rows, or describe the DataFrame.\n",
    "3. Please add two more features as an action. At least one of these should somehow interact with the DataFrame. Please be creative here. \n",
    "4. Give the program a welcome message that describes what you can do.\n",
    "5. Get the program a secret 'easter egg' action (such as typing \"happy\" to randomly print an inspirational message). \n",
    "\n",
    "Given that you can test this with the IMDB data and we created some interesting queries up above, perhaps think of a way to ask more involved questions or have the user select a question to answer from a set of canned questions.\n",
    "    \n",
    "Part of this task concerns how you take the basic DataFrame actions and link them together in Python methods (and maybe even Python objects). The use of `while` and a text input allows you to test program flow and some logic of looping. \n",
    "\n",
    "If you have explored object oriented program, there are a few ways to consider objects here but creating a new object or class isn't necessary.\n",
    "\n",
    "Rubric: \n",
    "Functioning: \n",
    "- Can use get (for row 1pt, for col 1pt, for cell 1pt)\n",
    "- Can use set (for cell 1pt)\n",
    "- Can exit (1pt)\n",
    "- Can loadcsv (1pt, note we will use a different csv to test)\n",
    "- Can list row length (1pt), column names (1pt)\n",
    "- Additional action 1. Should be using the DataFrame (2pts)\n",
    "- Additional action 2. (either on DF or elsewise, 2pts)\n",
    "- Does have easter egg (1pt)\n",
    "- Does have intro and/or help page (1pt)\n",
    "\n",
    "Robust:\n",
    "- Handles bad input gracefully (2pts)\n",
    "- Methods have at least a single comment explaining purpose (1pt)\n",
    "\n",
    "Elegant:\n",
    "- Has actions separated usefully into methods. (1pt)\n",
    "- Has other refactoring (subjective, 2pts)\n",
    "\n",
    "Creative: \n",
    "- Be creative. This might involve a useful help message, some interesting feature, or a refactoring that uses novel components. (5pts)\n",
    "\n",
    "That's 20 points total plus 5 points for creativity. It's hard to mark, so please treat mark as advisory. It does not count towards your summative mark.\n",
    "\n",
    "Qualitative assessment: \n",
    "- The TA may also write a short comment (1-2 sentences usually) describing the project and any potential mishaps or suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cec9704c-9197-4ca6-ab00-c745fe6afec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make a selection\n",
      "The DataFrame is loaded. It has 9694 rows\n",
      "Please make a selection\n",
      "[1915 1916 1919 1920 1921 1922 1923 1924 1925 1926 1927 1929 1928 1930\n",
      " 1931 1932 1933 1934 1935 1936 1937 1940 1938 1939 1941 1942 2001 1943\n",
      " 1944 1946 1945 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957\n",
      " 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971\n",
      " 1972 1973 1974 1975 1976 1977 1980 1978 1979 1981 1982 1983 1984 1985\n",
      " 1986 1988 1987 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999\n",
      " 2000 2005 2002 2003 2004 2008 2006 2007 2012 2021 2016 2009 2013 2018\n",
      " 2014 2015 2011 2019 2010 2017 2020 2022]\n",
      "Please make a selection\n",
      "Col 3: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       1915\n",
       "1       1916\n",
       "2       1919\n",
       "3       1920\n",
       "4       1921\n",
       "        ... \n",
       "9689    2019\n",
       "9690    2020\n",
       "9691    2020\n",
       "9692    2020\n",
       "9693    2019\n",
       "Name: startYear, Length: 9694, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make a selection\n",
      "Please make a selection\n",
      "Please make a selection\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "verbs = [\"get\",\"set\",\"loadcsv\",\"list\",\"exit\",\"list_cols\", \"get_unique\"]\n",
    "shapes = [\"row\",\"column\",\"cell\", \"df\"]\n",
    "\n",
    "def parse_text(text):\n",
    "    '''returns text separated by space'''\n",
    "    text_list = text.split()\n",
    "    text_phrase = {\"verb\":None,\"shapes\":None,\"var\":None}\n",
    "    \n",
    "    for i in verbs: \n",
    "        if i in text_list:\n",
    "            if text_phrase[\"verb\"] != None:\n",
    "                print(\"A statement should only have one verb\")\n",
    "                return None\n",
    "            text_phrase[\"verb\"] = i\n",
    "            text_list.pop(text_list.index(i))\n",
    "    \n",
    "    for i in shapes: \n",
    "        if i in text_list:\n",
    "            if text_phrase[\"shapes\"] != None:\n",
    "                print(\"A statement should only have one verb\")\n",
    "                return None\n",
    "            text_phrase[\"shapes\"] = i\n",
    "            text_list.pop(text_list.index(i))\n",
    "\n",
    "    # if len(text_list) == 1: \n",
    "    #     text_phrase[\"var\"] = text_list[0]\n",
    "    text_phrase[\"var\"] = text_list\n",
    "    \n",
    "    return text_phrase\n",
    "\n",
    "def get_row(df, row):\n",
    "    try:\n",
    "        ret = df.iloc[int(row)]\n",
    "        print(f'Row {row}: ')\n",
    "        display(ret)\n",
    "    except:\n",
    "        print('Invalid Row')\n",
    "\n",
    "def get_col(df, col): \n",
    "    try:\n",
    "        ret = df.iloc[:,int(col)]\n",
    "        print(f'Col {col}: ')\n",
    "        display(ret)\n",
    "    except:\n",
    "        print('Invalid Col')\n",
    "\n",
    "def get_cell(df, row, col):\n",
    "\n",
    "    try:\n",
    "        row_int = int(row)\n",
    "        col_int = int(col)\n",
    "    except:\n",
    "        print('Must Enter Number for Indices')\n",
    "\n",
    "    print(f\"Row {row}, Col {col}: {df.iloc[row_int, col_int]}\")\n",
    "\n",
    "\n",
    "def list_cols(df):\n",
    "    cols = df.columns.tolist()\n",
    "    print(f'{len(cols)} Columns : ')\n",
    "    display(cols)\n",
    "    \n",
    "def set_cell(df, row, col, val):\n",
    "    \n",
    "    try:\n",
    "        row_int = int(row)\n",
    "        col_int = int(col)\n",
    "        print(f\"Previous Value: {df.iloc[row_int, col_int]}\")\n",
    "        df.iloc[row_int, col_int] = val\n",
    "        print(f\"New Value: {df.iloc[row_int, col_int]}\")\n",
    "    except:\n",
    "        print('Must Enter Number for Indices')\n",
    "\n",
    "def get_unique_col(df, col):\n",
    "\n",
    "    try:\n",
    "        col_int = int(col)\n",
    "        print(df.iloc[:, col_int].unique())\n",
    "    except:\n",
    "        print(\"Must Enter Number for Column Index\")\n",
    "\n",
    "# def extra_func2(df): \n",
    "\n",
    "running = True\n",
    "while True: \n",
    "    print(\"Please make a selection\")\n",
    "    text = input()\n",
    "    if text == \"\": continue\n",
    "    \n",
    "    actions = parse_text(text)\n",
    "    if not actions: \n",
    "        print(\"Please try again or write type 'exit' to leave\")\n",
    "        continue\n",
    "    \n",
    "    # print(actions)\n",
    "    \n",
    "    if actions[\"verb\"] == \"exit\":\n",
    "        break\n",
    "    elif actions[\"verb\"] == \"loadcsv\":\n",
    "        # df = pd.read_csv(actions[\"var\"])\n",
    "        df = pd.read_csv(\"../data/imdb_over10k_votes_movies.csv\")\n",
    "        print(f\"The DataFrame is loaded. It has {len(df)} rows\")\n",
    "    elif actions[\"verb\"] == \"get\" and actions[\"shapes\"] == 'row':\n",
    "        get_row(df, actions[\"var\"][0])\n",
    "    elif actions[\"verb\"] == \"get\" and actions[\"shapes\"] == 'column':\n",
    "        get_col(df, actions[\"var\"][0])\n",
    "    elif actions[\"verb\"] == \"get\" and actions[\"shapes\"] == 'cell':\n",
    "        get_cell(df, actions[\"var\"][0], actions[\"var\"][1])\n",
    "    elif actions[\"verb\"] == \"list_cols\":\n",
    "        list_cols(df)\n",
    "    elif actions[\"verb\"] == \"set\" and actions[\"shapes\"] == 'cell':\n",
    "        set_cell(df, actions[\"var\"][0], actions[\"var\"][1], actions[\"var\"][2])\n",
    "    elif actions[\"verb\"] == \"get_unique\" and actions[\"shapes\"] == 'column':\n",
    "        get_unique_col(df, actions[\"var\"][0])\n",
    "\n",
    "# Note: loadcsv ../data/imdb_over10k_votes_movies.csv \n",
    "#       will work if your data is in a sibling folder called 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e9aa0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['a','bb','ccc']\n",
    "numbers = [1,2,3]\n",
    "\n",
    "min(numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fsd22env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "72ab57b0b5f2fd64aef2c7b60b3862b1a450b7cb33941b7430bf767e797b1ae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
