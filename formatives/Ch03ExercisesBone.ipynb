{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f94b4d7-69b5-442b-a9e6-c6653fcb5aa3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fundamentals of Social Data Science \n",
    "\n",
    "Week 1. Day 3. Exercises from Chapter 3 of FSStDS \n",
    "\n",
    "Within your study pod discuss the following questions. Please submit an individual assignment by 12:30pm Monday, October 17, 2022 on Canvas. \n",
    "\n",
    "These assignments have two sets of questions. The top questions have answers already in them. The last question is for you to submit. That last question will be given written feedback via the teaching assistants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bdf5e73-8712-42c6-b7a5-ec3040265e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# RUN THIS CELL IF YOU HAVE THE KEY \n",
    "# This is what we use to create the sample answers as encrypted text\n",
    "\n",
    "import pandas as pd \n",
    "import cryptography\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def encrypt(message: str, key: bytes) -> bytes:\n",
    "    return Fernet(key).encrypt(message.encode())\n",
    "\n",
    "def decrypt(token: bytes, key: bytes) -> str:\n",
    "    if not key: \n",
    "        return \"Hey now, why not try these on your own first?\"\n",
    "    return Fernet(key).decrypt(token).decode()\n",
    "\n",
    "# In case you're stuck or want to check your work, \n",
    "# uncomment the key and then run the sample answer cells. \n",
    "\n",
    "key = None\n",
    "\n",
    "key = b'_beepbeepbeepbeep1234567890beepbeepbeepbeep=' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99d8ef-0f7f-451e-ac04-a63420375604",
   "metadata": {},
   "source": [
    "# Shorter questions with answers\n",
    "\n",
    "These questions use a pre-chewed IMDB file of movies with over 10k votes on the platform. It's considerably smaller than the 760mb file of all movies. It should be available from Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcf4aa-da92-4dca-9d3b-7e68a9e5bf82",
   "metadata": {},
   "source": [
    "## Step 1. Read in the file. \n",
    "\n",
    "The first thing is to read in the file, `\"imdb_over10k_votes_movies.csv\"`. This is a list of movies from IMDB that have more than 10,000 votes on their ratings. I have prepared this data from a data export freely available from IMDB. The code for how I did it is in the appendix to this formative. \n",
    "\n",
    "There's conicidentally also about 10k movies in this data set. A big number but not too unwieldy for a personal computer. Herein, we are just going to practice asking and answering questions about this data. Most of what we are going to do with these questions is rank, summarise, and compare. We might want to compare the runtimes of movies of different genres or ratings.\n",
    "\n",
    "To get you started, check that your DataFrame looks similar to the one here from this code. For the example answer I stored the file in an adjacent folder called `data`, so for me that is why the path looks like so. I similarly recommend you having a separate folder for your data just in a sibling folder to this one (rather than a 'subfolder' within this one). As in: \n",
    "\n",
    "~~~\n",
    "- FSDS\n",
    "  - Data\n",
    "    - imdb_over10k_votes_movies.csv\n",
    "  - Formatives\n",
    "    - SURNAME_INIT_WD21_w1formative_DataFramePratice.ipynb\n",
    "  - Summative \n",
    "  - Readings\n",
    "  etc...\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b059cac4-af19-4fa8-a6d4-befe9913965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9694 entries, 0 to 9693\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   tconst          9694 non-null   object \n",
      " 1   primaryTitle    9694 non-null   object \n",
      " 2   originalTitle   9694 non-null   object \n",
      " 3   startYear       9694 non-null   int64  \n",
      " 4   runtimeMinutes  9694 non-null   int64  \n",
      " 5   averageRating   9694 non-null   float64\n",
      " 6   numVotes        9694 non-null   int64  \n",
      " 7   genre1          9694 non-null   object \n",
      " 8   genre2          8840 non-null   object \n",
      " 9   genre3          6361 non-null   object \n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 757.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 1 answer below (ensuring your file is in the right folder)\n",
    "from pathlib import Path\n",
    "\n",
    "movie_df = pd.read_csv(\"../data/imdb_over10k_votes_movies.csv\")\n",
    "\n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4815292c-05ef-426f-884b-bec049594c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your output should look like this: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9694 entries, 0 to 9693\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   tconst          9694 non-null   object \n",
      " 1   primaryTitle    9694 non-null   object \n",
      " 2   originalTitle   9694 non-null   object \n",
      " 3   startYear       9694 non-null   int64  \n",
      " 4   runtimeMinutes  9694 non-null   int64  \n",
      " 5   averageRating   9694 non-null   float64\n",
      " 6   numVotes        9694 non-null   float64\n",
      " 7   genre1          9694 non-null   object \n",
      " 8   genre2          8840 non-null   object \n",
      " 9   genre3          6361 non-null   object \n",
      "dtypes: float64(2), int64(2), object(6)\n",
      "memory usage: 757.5+ KB\n"
     ]
    }
   ],
   "source": [
    "ans = b'gAAAAABh6UcLaoFySY7xkY_0mmZk5vkcNgqUdZpLg1CW04bMW3E-pKGS2js4S19wn5ja0Z3jrkpzf6siH_x_5C0oj_rFHAuRnNXk_zyGKTtmkube7-Ha6uO9LEt3T6cHMPu4wXSmF1oLp5bja_HeQw5Xs0IDyTW5D3ZW_9acMPEOEPjOZ7-XrsKWXLkAdZLBxIY-c2JyfGX8fv7FRwkMEFz1H4hGKOhip77mFH_vMEhxCtChIE7EoSN5NqV9BaSm9gl4nYjNjvRLI93Q3aOV0sRVXXBlDE7GE6vcgvDmZL5wJLHTn1pJN6ZycN6iU5F10Sef6SwW9l1AO26U95O02b_U-hFaiLnMEw04_0VCay0ZG0Feuc9NuQVn9cs0B43am5XuIM9kAdlAOXUmmLw9YE-f8VB5877l1rnhBddp10yPtgFBr0pGYFfpzj_tZj48190xKLEd2R1CV5mngQqx557MDZ_9XSFCq3JG-IoEQqdkc_1nHEhkqS0NzfapMGgkQh1vMnIn4opLy-51iBp3SpRi0VsfPke_3PgvAoO6T-Ntrowf-nZtW-W2s8TJQ8pj6-OCTw3ti74TFyguenw2WbPCf-HzcnnabHbFa7NYkDcXoJSN7Dnxri9slpAp6iIk3hyAqWPhDZjyPv90eCjivKuCL63Y-mhEFEKhSziHm4cMpWF2fxyYJs3y69buaQqefNFTV9VMFeO9Dj-qTA1YUCFh5AU0R5eTOkWq7-hB6yh3Qmvy6ZbbU93gcEHc-nd8nLsTCvftODXZKgqkj5NjYrSK9VjtVSc3tGQ2w8b4mAre_ahQtq54fY1yFj6GF_5KByc6cOqiWwqKpNp6GifV6Z6KT0FVj6GujflT4JDry1a8JbmtrD6-wp7ONPQ2cJlQE5HL_wxcmyiY5nDkiXGQO27-obhsJaz5gDNFMfrZFZ18kHnwqFroZaj6ZvFVxLdnH-OddoNvUDg5_lr6XvEZj1z0FHSjPRI1mWL-5BeEbGyGqQAkoCN-vJYcx8KUiLwHaKtKhMwA99HoLgL-Avqi6jHWICdm96Ye0TVav55E0T_m5SFcWwr4huM='\n",
    "\n",
    "print(decrypt(ans, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad1901-1a63-4851-9c3e-2e5f326be980",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2. Learn about the data set. \n",
    "\n",
    "Below are some questions to ask about the data set. I have printed some answers. Your job is to fill in the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73506cdc-24b7-428d-8521-a2d591ae199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this data set are 9694 in total.\n",
      "The movie with the lowest rating is Cumali Ceber: Allah Seni Alsin with a rating of 1.0.\n",
      "The movie with the highest rating is The Shawshank Redemption with a rating of 9.3.\n"
     ]
    }
   ],
   "source": [
    "num_movies = len(movie_df)\n",
    "ordered = movie_df.sort_values(by=['averageRating'])\n",
    "lowest_rating = ordered.head(1)['averageRating'].iloc[0]\n",
    "lowest_rating_name = ordered.head(1)['originalTitle'].iloc[0]\n",
    "highest_rating = ordered.tail(1)['averageRating'].iloc[0]\n",
    "highest_rating_name = ordered.tail(1)['originalTitle'].iloc[0] \n",
    "\n",
    "print(f\"In this data set are {num_movies} in total.\") \n",
    "print(f\"The movie with the lowest rating is {lowest_rating_name} with a rating of {lowest_rating}.\")\n",
    "print(f\"The movie with the highest rating is {highest_rating_name} with a rating of {highest_rating}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d6997ae-cf16-43bb-8266-df33021b78b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# In case two or more movies share a top (or bottom) rating,\n",
      "# we take one with most votes.\n",
      "\n",
      "# Using .min() will get us the minimum of a series.\n",
      "# To remind movie_df[\"averageRating\"] is the same as movie_df.averageRating\n",
      "lowest_rating = movie_df.averageRating.min()\n",
      "\n",
      "# This creates a dataframe for all movies with the lowest_rating\n",
      "temp_df = movie_df[movie_df.averageRating == lowest_rating]\n",
      "\n",
      "# This puts the movie with the most votes at the bottom\n",
      "temp_df = temp_df.sort_values(\"numVotes\")\n",
      "\n",
      "# This asks for row at bottom (iloc[-1]) and then for 'primaryTitle'\n",
      "lowest_rating_name = temp_df.iloc[-1][\"primaryTitle\"]\n",
      "\n",
      "# If instead you sort descending\n",
      "temp_df.sort_values(\"numVotes\", ascending=False, inplace = True)\n",
      "\n",
      "# Then you would look for the 0 row instead of the last (i.e. -1) row\n",
      "lowest_rating_name = temp_df.iloc[0][\"primaryTitle\"]\n",
      "\n",
      "\n",
      "\n",
      "highest_rating = movie_df.averageRating.max()\n",
      "temp_df = movie_df[movie_df.averageRating == highest_rating]\n",
      "temp_df = temp_df.sort_values(\"numVotes\", ascending = False)\n",
      "highest_rating_name = temp_df.iloc[0][\"primaryTitle\"]\n",
      "\n",
      "\n",
      "print(f\"In this data set are {num_movies} in total.\") \n",
      "print(f\"The movie with the lowest rating is {lowest_rating_name} with a rating of {lowest_rating}.\")\n",
      "print(f\"The movie with the highest rating is {highest_rating_name} with a rating of {highest_rating}.\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans = b'gAAAAABh6Uhn5K1CBvVi-kmnwLUj1bwYTgtNsO7BgdRlHigpsRPj3R60acHEg7b8HAPtidj6UY5j39MAPoXf24MkbtzLj--_RPj4KrNSWWODKIG4_KwmRUap3_u17SxklPscaOUOQkl_1NNjAZ4uh8nNe1u5Jbrgo6KtyUV54BNjrhkTx6rwi-1K-VbzL17TSEkARKI8z42xmZBVTl5rkPA_P6PdOy_pFisZjcYfplFVvHOe4A25xg_nGguMVtvC_4b9gOJzVZ-LGvwASUS115rokK3H4LtZtyjJUQyUuRpgfMfMaX-EhuUHxbBEvmovcdDePRRp_qUWH7_B7pYQ3wI6Y54vnEPZ6WyVC5x4KDpU7QtyozW_ziv0VT9fApTcfsn2BWEXMuUsDAChbXXxgDVv-Q02Jh12S9gLgJJsd-58jBar-wePIoGe5__5Dhx8OGPno1ACM-NTbmyj99C6Np8M-QLZVC2vnqgk0kQTNfIC992vq17FxUdWJvfxVnLVaxwsQxYaGnZ-54fCTo5EXoOCgBiOstanvdIIgWK2XRLBKQSYzb8QGTR4S04h3J2sdXkgs7AS_2Xkso9-HHlqdKBwhfz24rgFKR82Kl14IQq-lTXbwElIHCR5h6GY5x0V1YCyZoubsBPzYaGNPOig3wk7u4zpzGehs2EL94cLHz5XvDA-kSdWFfwoRmwipH5zuj0axp3QqSs2eXYZHy_v6QDvF5BXSWqv2MqkHxepG0cQtBVD5v7f95tgTQ8GOSwqyIomo-YfQog2LLAIMw5qrSaM7_WG67Z2cf5fjDWrSNGv6uxHQK9wwTcZUV-7w-vhUqOYy94X17K_cBO89Fut51qH_mDypu54OBYaQGZ_3s4pQW0wfzROMEnpeBoFu5IUcKCQPd9hQkiCSbt3rKyBtUPCRYZXhvGQcajqli2NsR35r3ojN3BWgwZgeZPHP-MOuROd_tB_BvqR-oyUpwOsRc9GvjHBR-wd1qiTics8WU2NREyZedaK5pjXc7bdxKrTfmfXrjCp1HT7KplHgjrT0d8tp8Kei3aflmT9f2akGTpJf7vJpw_l7qbPgWP9Eexx-oKHpsC0JX43nXG0vXgjYvLz8NhULeivxo4GfAIXOe-Q-AIgtcIEV8k7Q7l49_bdH55zwIPz2xd9u36iMsdXHG2POJYC1lO0YuYRWFe7SGihONGvMnsk-Ay4DlkD844RXNkzWIpg2ngW6MwYkvi64ecIn37l_3MuUOQP-x1eBfYezcTYLG7VBkkEXiRXO9ML0F7hulfRoyhwqUqdbNoDXDTovE0j9yRr5rfxCAQIYnmOquHml3fBf15zY4MWkjI7Mozwy_kQCYoJ9orOj6mvSqU8_eXwz83EbFMhtOkkOriBiwteaE_Dqh4WcCHq_07rihNs525oQJmSpENL2NnCrYXX-8Z3gI7dR94bgOHhzHVWf6sOISzbpLY5gZM-yF1tePs-Inta3aoc7GVjkzqZiNMVT4AkV4L9cx9ClSwzKGlpXOavax2h8nK9EijGOZ9KrIyyfrNSnMNVffRZwLdyyL6GhHClwCALVoerPzUF2D1SEnxDN2s1RwtiBSIF1YfI9xKYRXou1KOkxdILQyJH4vKzR7EL9VBVZUSg3zHkUTfiY6PQRMYKdkadUw9sbA21kqwG5p6XOEWzrfCdFeHv-Gh4ifshttoFL20_9FX3PxCpzz7iRPa5aL39t5YWhOp-t2nWeQx1Wf1SyGeA7LU3K4gdVAyzlR4zonHuAuotouLcFdE4n_Ew9aW6Y84cZTyAHS1TNXVbvEpirO_ywVGFGjJeBa-0O_mIhJBXuLph6WLFx5RMfdjDDnQ='\n",
    "\n",
    "print(decrypt(ans, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc9d12-79c0-4a1c-a33e-136aa78fed6e",
   "metadata": {},
   "source": [
    "## Step 3. Compare some groups \n",
    "\n",
    "### First comparison - some arbitrary cut points. \n",
    "Let's create some groups and look at the scores within these groups. This is a comparison of means (which is a pre-cursor to a `t-test` which asks \"these means have different numbers, but are they _significantly_ different\". You do not have to do a t-test here, just report the mean differences. \n",
    "\n",
    "We are using somewhat arbitrary cut-points. Cut the data to all movies with a rating of 8 or more to all movies with a rating of 5 or less. \n",
    "\n",
    "Then we can ask, do higher rated movies have a shorter or longer runtime than lower rated movies? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20381282-5cc4-417a-a5fc-58f52e609acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this data set are 769 movies with an average score of 8 or more.\n",
      "These movies have an average runtime of 127.79 minutes.\n",
      "In this data set are 562 movies with an average score of 5 or less.\n",
      "These movies have an average runtime of 98.25 minutes.\n"
     ]
    }
   ],
   "source": [
    "above8 = movie_df[movie_df['averageRating'] >= 8]\n",
    "num_above8 = len(above8)\n",
    "avg_above8 = above8['runtimeMinutes'].mean()\n",
    "\n",
    "below5 = movie_df[movie_df['averageRating'] <= 5]\n",
    "num_below5 = len(below5)\n",
    "avg_below5 = below5['runtimeMinutes'].mean()\n",
    "\n",
    "\n",
    "print(f\"In this data set are {num_above8} movies with an average score of 8 or more.\")\n",
    "\n",
    "print(f\"These movies have an average runtime of {avg_above8:0.2f} minutes.\")\n",
    "\n",
    "print(f\"In this data set are {num_below5} movies with an average score of 5 or less.\")\n",
    "\n",
    "print(f\"These movies have an average runtime of {avg_below5:0.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76493106-ca43-4f1a-94d6-288eaffcd0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "above8 = movie_df[movie_df.averageRating >= 8]\n",
      "num_above8 = len(above8)\n",
      "avg_above8 = above8.runtimeMinutes.mean()\n",
      "\n",
      "below5 = movie_df[movie_df.averageRating <= 5]\n",
      "num_below5 = len(below5)\n",
      "avg_below5 = below5.runtimeMinutes.mean()\n",
      "\n",
      "\n",
      "print(f\"In this data set are {num_above8} movies with an average score of 8 or more.\")\n",
      "\n",
      "print(f\"These movies have an average runtime of {avg_above8:0.2f} minutes.\")\n",
      "\n",
      "print(f\"In this data set are {num_below5} movies with an average score of 5 or less.\")\n",
      "\n",
      "print(f\"These movies have an average runtime of {avg_below5:0.2f} minutes.\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans = b'gAAAAABh6UkhBWikSoloTo-xjoGch1v1aWxtbsvOB5h1F594T_Z0_y346UE66HJGm819Qu9K8HoelHN5y7drCw1F5I--WRaxQdkkKSZSBMwNDI_EzaNYlMX-7yIdJKR-noLjNs8kgRXSQ4Vp6a38X1gXwdoDMqpCLlKu8gA6o1pRDjptbBDp8CNiloK93RKCZrMKkfh1O7Pp640SRWCKAZ0UY8oIRmpr77sdh9n9fxULf_g-8nCUswqO1qGJytHITSmT1UODQP76Op7NOqTEViguuweELUd5Zzv8KPvwvGaMwi1dKoPzGrvfMaUkKrd6v6CQ7iMwkijL4gXkndFaC7_3nV3dDEEUsnf41pN6CEiqOZnMu1srpwW_OWbmVnwwD5MGR9f_fxJHXVXrJHo8D-m4SJSjgyHrSbzLn_1mY4m1PPrOnfnjpyEAHBWVgttK-t7qRlhwjYW7b_9hvtITVk9zv9_ga18UUYtEscl0ep0Hy-u0fejkraZfgt1aYX7khDldH-wEH4RH3hac-Zq2TLxKLJg7udp0g1Dj_522LR9qUVIBHkbDNwcTr-YXpm5K8WUbbYvh3Z6w3lWjJdYD1tvO0SOUw2NSiudbK06o0qwi4sTBxmVS1dIzDgxoGlxxfdVGOtj8JfhRXXsTSZ9uJlOnHI9Nh_Kuk80Y2LQJHZu3ciYVCQ7nNiqbo8l2zhbR7rKHwyqZPKYDmAhBrsXI3YzB-g6uKqdCPyU0ApxOSCSe8uCeQxrumfo_PGHwPA2iE3KtKsjhJD6HKcjyS68EhFeQBqgKMiC7bhuw9E1PZQwabUDVuAfX3gnjXT975AT93WnkJ2xBzHL9'\n",
    "\n",
    "print(decrypt(ans,key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f5f5b-cde3-4503-943f-b5f0429973d5",
   "metadata": {},
   "source": [
    "### Second comparison - between genres\n",
    "\n",
    "The data have three genre columns. Compare the ratings of movies in the `'Comedy'` genre to those in the `'Drama'` genre. The simplest way would be to mask by `[movie_df.genre1 == 'Comedy']`. But what about the other two columns? Sometimes movies are classed as 'Comedy' and 'Western'.\n",
    "\n",
    "How might you account for those?  Here's a hint: if you have two columns to put in your comparison statement, you put them each in their own parenthesis and then use `|` as the *OR* symbol (as well as `&` for the _AND_ symbol). So we might say:\n",
    "\n",
    "~~~ python\n",
    "short_or_long = movie_df[(movie_df.runtimeMinutes < 90) | (movie_df.runtimeMinutes > 180)]\n",
    "long_and_bad = movie_df[(movie_df.runtimeMinutes > 150) & (movie_df.averageRating < 6)]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2dfbecd-6bb5-4584-9027-0a120af3a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the data set there were 3544 Comedy movies.\n",
      "They had an average score of 6.5.\n",
      "In the data set there were 5388 Drama movies.\n",
      "They had an average score of 6.9.\n"
     ]
    }
   ],
   "source": [
    "comedy = movie_df[(movie_df['genre1'] == 'Comedy') | (movie_df['genre2'] == 'Comedy') | (movie_df['genre3'] == 'Comedy')]\n",
    "num_comedy = len(comedy)\n",
    "avg_comedy = comedy['averageRating'].mean()\n",
    "\n",
    "drama = movie_df[(movie_df['genre1'] == 'Drama') | (movie_df['genre2'] == 'Drama') | (movie_df['genre3'] == 'Drama')]\n",
    "num_drama = len(drama)\n",
    "avg_drama = drama['averageRating'].mean()\n",
    "\n",
    "print(f\"In the data set there were {num_comedy} Comedy movies.\")\n",
    "print(f\"They had an average score of {avg_comedy:0.1f}.\")\n",
    "\n",
    "print(f\"In the data set there were {num_drama} Drama movies.\")\n",
    "print(f\"They had an average score of {avg_drama:0.1f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca8b860d-a1a3-4c12-80dd-3ac81df379a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all_comedy = movie_df[(movie_df.genre1 == 'Comedy') |  \n",
      "                      (movie_df.genre2 == 'Comedy') | \n",
      "                      (movie_df.genre3 == 'Comedy') ]\n",
      "\n",
      "all_drama = movie_df[(movie_df.genre1 == 'Drama') |  \n",
      "                      (movie_df.genre2 == 'Drama') | \n",
      "                      (movie_df.genre3 == 'Drama') ]\n",
      "\n",
      "#########################\n",
      "# Or, here's a more abstracted way: \n",
      "\n",
      "def get_genre_subset(df, genre):\n",
      "    return df[(df.genre1 == genre) |  \n",
      "              (df.genre2 == genre) | \n",
      "              (df.genre3 == genre) ]\n",
      "\n",
      "all_comedy = get_genre_subset(movie_df, \"Comedy\")\n",
      "all_drama = get_genre_subset(movie_df, \"Drama\")\n",
      "\n",
      "\n",
      "num_comedy = len(all_comedy)\n",
      "avg_comedy = all_comedy.averageRating.mean()\n",
      "\n",
      "print(f\"In the data set there were {num_comedy} Comedy movies.\")\n",
      "print(f\"They had an average score of {avg_comedy:0.1f}.\")\n",
      "\n",
      "num_drama = len(all_drama)\n",
      "avg_drama = all_drama.averageRating.mean()\n",
      "\n",
      "print(f\"In the data set there were {num_drama} Drama movies.\")\n",
      "print(f\"They had an average score of {avg_drama:0.1f}.\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans = b'gAAAAABh6Une6ifsZylGBSvBLkJvbqYy1oMtajxVva10OsyTaXqvt3S5UwzvSCG6ei2GTS1Z2hiweFSyKG4WZna5er5hbvKIlaCsA_AU3XNsGrKINA_RnA1028vSnlobRBK1dcY3TXmwYUIE6k1a_N5v_WboCxfO8mCvVg4Y2KGTS4cIqc-Ct-adKd8W1xXsOjgFscg7ZB847FZsIZ5idqM9heQH7BOIWK3j_cyBn9Fg0zaYVJK5zrrhXDFwBU9O9AXSjRjRLmwM6tjkeIWQ2zAHpNWWd29JYD60sSPuuSvDH4sWia0cOAek13p_eMIG5EDCyg_kAAB1od2dIz2MMH5tagpAYy7hiXyEALQ0aFfkUoW9PBPSm4RhpcBLxgTYX7wDOeOoufg28z7cewS-KzyEFbC6SxueT_6S1niD0Bw1OVu94dAw-lmilIkHy3zEHZg8K-aVVpyVWGl7ypGRqpaMEJKmxHl5w_fx1itZXF7mCGsV7ExAodn_tMhnWrYOao61XU1er8MRJe4sM5alwf1NhEaRl_01BnjLlNcG4BaSIq4UxOmH1C8xqc3X8cr6obAYcjORUUMhqZhg75UCKMXL-YmG-rkBxiYePJU16QizlfoxkRxxSEk-F_qQMUTXdBa7pRl0NOFGYb3ffL78GfGOIMkFhsv_2VKsGK5jn7aKeow2QXac0kaCEtfPWuicvbSkkn-wzbWrJmIxEojQv2vWHYQc_zJ12VFvvcSi3ll0X8CWytvmFZdCeUDB6Kzg7cTi5oydjd290QuQxc5-iTf0yQFmoYQeB9rbL7RuAPij1AbIW64Pt_uY2PxtsIa3JKfDGwZrU1Whm1w4klp-ul8mb4otNmMWZJun62atQ53h01FzavbSMXqAcxs3gjqMfmHQfYutyvFAvYnpGGUUE--styNui6PvFMyq9QGaOuFBqzlRKn1dXo-B0moVpeTXM4M4yiI-wlYreeAiUrZEt3b_vnvsrtuKWlh1MHfCcHP4kOy-4AI3aSrgnYAEJdJMI_bse0f0WtRKWyYWsj9-xsBunH4G2-BCofQGfF1h2pjuxhX-9k3BfXPM3lRR8isllY_RBcwIg-Jb1FFpoNDWOQ6pG_zYiEV3fg_eo8xdWLIpx2DJ1UqjkFYOnpH6iU8JmmU9wJyjafHFPi-W6tfila1BLbD9Ddy7dr2Vb8MBXE4ItTe22nVP3ASTZ_59PYFCXdCM8g9Gbj4xmRcn-hg6DWK9i4VD3Sbe1xFih5kOmYXHh3NTpVcxxirPSLQPzBBwE7w4SHUMp1I3y1tpptsWCC6vyuPMy62TSQdhWrfigX2i5kFUBJGUQlU5m7XjNvCWcJP63wcv-LzYVNamG6JKttO-Jfo2uoPDAMaH0uaX3Kok2DfzYotk5czRVJlMBrmFZQx5FHgpP59Ouf6i6t9CS6vf8B0AxqZY9B1Bbvm_BVPqzLThLD97Uq8='\n",
    "\n",
    "\n",
    "print(decrypt(ans,key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40bc89e8-9c87-48b4-9e72-b77a16c95fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "def encrypt(message: str, key: bytes) -> bytes:\n",
    "    return Fernet(key).encrypt(message.encode())\n",
    "\n",
    "def decrypt(token: bytes, key: bytes) -> str:\n",
    "    if not key: \n",
    "        return \"Please wait for the key - try these on your own!\"\n",
    "    return Fernet(key).decrypt(token).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74e4b02b-d8e9-4593-9657-dec45bb97f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note these are not encrypted below\n",
    "key = b'fundamentalsofsocialdatasciencemichaelmas22_' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebde3ff-3476-4529-88cd-f838b5562a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19aaf0e-d810-4053-98a4-e878d8ae3824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216b578-1d44-4487-8823-360fe23f545f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1791cd5f-5181-4132-b5cb-3e24ea1e4ab3",
   "metadata": {},
   "source": [
    "# The long question: Build a query machine \n",
    "\n",
    "For this long question you are asked to build and submit (either here in a cell or as a separate .py file) a script that will allow someone to query a data frame using text. \n",
    "\n",
    "Below are some skeleton code to help you get going. You will notice that currently you can:\n",
    "- Enter a verb, shape, and variable which will be parsed.\n",
    "- Two verbs have been implemented: `loadcsv` which will load a csv as a DataFrame and `exit` which will exit the program. \n",
    "- Please create a means to use the verb \"get\" to return a row, a column, or a single cell.\n",
    "\n",
    "1. Please create a means to use \"set\" to set the value of a single cell \n",
    "2. Please create a means to use \"list\" to display either the columns, number of rows, or describe the DataFrame.\n",
    "3. Please add two more features as an action. At least one of these should somehow interact with the DataFrame. Please be creative here. \n",
    "4. Give the program a welcome message that describes what you can do.\n",
    "5. Get the program a secret 'easter egg' action (such as typing \"happy\" to randomly print an inspirational message). \n",
    "\n",
    "Given that you can test this with the IMDB data and we created some interesting queries up above, perhaps think of a way to ask more involved questions or have the user select a question to answer from a set of canned questions.\n",
    "    \n",
    "Part of this task concerns how you take the basic DataFrame actions and link them together in Python methods (and maybe even Python objects). The use of `while` and a text input allows you to test program flow and some logic of looping. \n",
    "\n",
    "If you have explored object oriented program, there are a few ways to consider objects here but creating a new object or class isn't necessary.\n",
    "\n",
    "Rubric: \n",
    "Functioning: \n",
    "- Can use get (for row 1pt, for col 1pt, for cell 1pt)\n",
    "- Can use set (for cell 1pt)\n",
    "- Can exit (1pt)\n",
    "- Can loadcsv (1pt, note we will use a different csv to test)\n",
    "- Can list row length (1pt), column names (1pt)\n",
    "- Additional action 1. Should be using the DataFrame (2pts)\n",
    "- Additional action 2. (either on DF or elsewise, 2pts)\n",
    "- Does have easter egg (1pt)\n",
    "- Does have intro and/or help page (1pt)\n",
    "\n",
    "Robust:\n",
    "- Handles bad input gracefully (2pts)\n",
    "- Methods have at least a single comment explaining purpose (1pt)\n",
    "\n",
    "Elegant:\n",
    "- Has actions separated usefully into methods. (1pt)\n",
    "- Has other refactoring (subjective, 2pts)\n",
    "\n",
    "Creative: \n",
    "- Be creative. This might involve a useful help message, some interesting feature, or a refactoring that uses novel components. (5pts)\n",
    "\n",
    "That's 20 points total plus 5 points for creativity. It's hard to mark, so please treat mark as advisory. It does not count towards your summative mark.\n",
    "\n",
    "Qualitative assessment: \n",
    "- The TA may also write a short comment (1-2 sentences usually) describing the project and any potential mishaps or suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cec9704c-9197-4ca6-ab00-c745fe6afec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "        Welcome to RESTful Pandas! ʕ◕ᴥ◕ʔ\n",
      "        We're a Pandas Dataframe wrapper that vaguely reminds you of a REST API\n",
      "\n",
      "        Commands:\n",
      "        loadcsv <filepath>; get row <rowindex>; get column <columnindex>;\n",
      "        get cell <rowindex> <columnindex>; list column; list indices\n",
      "        post cell <rowindex> <columnindex> <value>; get unique_col <columnindex>\n",
      "        get perc_missing; eminem\n",
      "        \n",
      "Please make a selection\n",
      "\n",
      "    *** \n",
      "    Lyrics are generated from Eminem's uncensored discography. \n",
      "    Question for Consideration: What is it okay for machines to say?\n",
      "    ***\n",
      "        \n",
      "Maybe I needed to grow up to be just like me?\n",
      "All you do is cheat me out of my house is lawn\n",
      "Burst upon the scene and seen that the world was over this whole Y2K thing\n",
      "Nah, I guess not, what the fuck? Son of a bitch\n",
      "\n",
      "Please make a selection\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import markovify\n",
    "import requests\n",
    "import time\n",
    "\n",
    "verbs = [\"get\",\"post\",\"loadcsv\",\"list\",\"exit\",\"list_cols\", \"eminem\",\"help\"]\n",
    "shapes = [\"row\",\"column\",\"cell\", \"df\", \"unique_col\",\"perc_missing\"]\n",
    "\n",
    "def parse_text(text):\n",
    "    '''returns text separated by space'''\n",
    "    text_list = text.split()\n",
    "    text_phrase = {\"verb\":None,\"shapes\":None,\"var\":None}\n",
    "    \n",
    "    for i in verbs: \n",
    "        if i in text_list:\n",
    "            if text_phrase[\"verb\"] != None:\n",
    "                print(\"A statement should only have one verb\")\n",
    "                return None\n",
    "            text_phrase[\"verb\"] = i\n",
    "            text_list.pop(text_list.index(i))\n",
    "    \n",
    "    for i in shapes: \n",
    "        if i in text_list:\n",
    "            if text_phrase[\"shapes\"] != None:\n",
    "                print(\"A statement should only have one verb\")\n",
    "                return None\n",
    "            text_phrase[\"shapes\"] = i\n",
    "            text_list.pop(text_list.index(i))\n",
    "\n",
    "    # if len(text_list) == 1: \n",
    "    #     text_phrase[\"var\"] = text_list[0]\n",
    "    text_phrase[\"var\"] = text_list\n",
    "    \n",
    "    return text_phrase\n",
    "\n",
    "def get_row(df, row):\n",
    "    '''returns the row matching the given index'''\n",
    "    try:\n",
    "        ret = df.iloc[int(row)]\n",
    "        print(f'Row {row}: ')\n",
    "        display(ret)\n",
    "    except:\n",
    "        print('Invalid Row')\n",
    "\n",
    "def get_col(df, col): \n",
    "    '''returns the column matching the given index'''\n",
    "    try:\n",
    "        ret = df.iloc[:,int(col)]\n",
    "        print(f'Col {col} ({df.columns[int(col)]}): ')\n",
    "        display(ret)\n",
    "    except:\n",
    "        print('Invalid Col')\n",
    "\n",
    "def get_cell(df, row, col):\n",
    "    '''returns the cell at the given row and column index'''\n",
    "    try:\n",
    "        row_int = int(row)\n",
    "        col_int = int(col)\n",
    "        print(f\"Row {row}, Col {col} ({df.columns[col_int]}): {df.iloc[row_int, col_int]}\")\n",
    "    except:\n",
    "        print('Must Enter Number for Indices')\n",
    "\n",
    "def list_cols(df):\n",
    "    '''returns a list of column names'''\n",
    "    cols = df.columns.tolist()\n",
    "    print(f'{len(cols)} Columns : ')\n",
    "    display(cols)\n",
    "\n",
    "def list_rows(df):\n",
    "    '''returns a list of row indices'''\n",
    "    indices = df.index.tolist()\n",
    "    print(f'{len(indices)} Rows (displaying by indices): ')\n",
    "    display(indices)\n",
    "    \n",
    "def post_cell(df, row, col, val):\n",
    "    '''sets the new value of a cell at the given row and column index'''\n",
    "    try:\n",
    "        row_int = int(row)\n",
    "        col_int = int(col)\n",
    "        print(f\"Previous Value: {df.iloc[row_int, col_int]}\")\n",
    "        df.iloc[row_int, col_int] = val\n",
    "        print(f\"New Value: {df.iloc[row_int, col_int]}\")\n",
    "    except:\n",
    "        print('Must Enter Number for Indices')\n",
    "\n",
    "def get_unique_col(df, col):\n",
    "    '''returns a list of the unique values in a column'''\n",
    "    try:\n",
    "        col_int = int(col)\n",
    "        print(f'Unique values in {df.columns[col_int]}:')\n",
    "        print(df.iloc[:, col_int].unique())\n",
    "    except:\n",
    "        print(\"Must Enter Number for Column Index\")\n",
    "\n",
    "def get_perc_missing(df): \n",
    "    '''returns the percent of the dataframe that has missing values'''\n",
    "    n_cols = len(df.columns)\n",
    "    n_rows = len(df)\n",
    "    n_missing = df.isna().sum().sum()\n",
    "    perc = n_missing / (n_cols * n_rows)\n",
    "    print(f\"{perc:.2%} of the data is missing\")\n",
    "\n",
    "def eminem():\n",
    "    '''uses a markov chain to generate eminem-like rap lyrics'''\n",
    "    print(\n",
    "        \"\"\"\n",
    "    *** \n",
    "    Lyrics are generated from Eminem's uncensored discography. \n",
    "    Question for Consideration: What is it okay for machines to say?\n",
    "    ***\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    req = requests.get('https://raw.githubusercontent.com/mariostrbac/eminem-lyrics-generator/main/data/processed/eminem_lyrics.csv')\n",
    "\n",
    "    text = req.text\n",
    "    text = re.sub('\\[.*\\]', '', text)\n",
    "    text = re.sub('\\n\\n', '\\n', text)\n",
    "    text = re.sub('\"\"', '\"', text)\n",
    "\n",
    "    markov_text = markovify.NewlineText(text, state_size=3)\n",
    "\n",
    "    for i in range(4):\n",
    "        next_bar = None\n",
    "        while next_bar is None:\n",
    "            next_bar = markov_text.make_sentence(tries = 50)\n",
    "        print(next_bar)\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "help =  \"\"\" \n",
    "        Welcome to RESTful Pandas! ʕ◕ᴥ◕ʔ\n",
    "        We're a Pandas Dataframe wrapper that vaguely reminds you of a REST API\n",
    "\n",
    "        Commands:\n",
    "        loadcsv <filepath>; get row <rowindex>; get column <columnindex>;\n",
    "        get cell <rowindex> <columnindex>; list column; list indices\n",
    "        post cell <rowindex> <columnindex> <value>; get unique_col <columnindex>\n",
    "        get perc_missing; eminem\n",
    "        \"\"\"\n",
    "\n",
    "print(help)\n",
    "time.sleep(1)\n",
    "\n",
    "running = True\n",
    "while True: \n",
    "\n",
    "    print(\"Please make a selection\")\n",
    "    text = input()\n",
    "    if text == \"\": continue\n",
    "    \n",
    "    actions = parse_text(text)\n",
    "    if not actions: \n",
    "        print(\"Please try again or write type 'exit' to leave\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        if not actions[\"verb\"] in ['eminem', 'exit', 'loadcsv']:\n",
    "            df.columns\n",
    "    except NameError as e:\n",
    "        print(\"Please use 'loadcsv <filename>' first\")\n",
    "        continue\n",
    "    \n",
    "    if actions[\"verb\"] == \"exit\":\n",
    "        break\n",
    "    elif actions[\"verb\"] == \"loadcsv\":\n",
    "        try:\n",
    "            df = pd.read_csv(actions[\"var\"][0])\n",
    "            #df = pd.read_csv(\"../data/imdb_over10k_votes_movies.csv\")\n",
    "            print(f\"The DataFrame is loaded. It has {len(df)} rows\")\n",
    "        except: \n",
    "            print('Invalid csv file')\n",
    "    elif actions[\"verb\"] == \"help\":\n",
    "        print(help)\n",
    "    elif actions[\"verb\"] == \"get\" and actions[\"shapes\"] == 'row':\n",
    "        get_row(df, actions[\"var\"][0])\n",
    "    elif actions[\"verb\"] == \"get\" and actions[\"shapes\"] == 'column':\n",
    "        get_col(df, actions[\"var\"][0])\n",
    "    elif actions[\"verb\"] == \"get\" and actions[\"shapes\"] == 'cell':\n",
    "        get_cell(df, actions[\"var\"][0], actions[\"var\"][1])\n",
    "    elif actions[\"verb\"] == \"list\" and actions[\"shapes\"] == 'column':\n",
    "        list_cols(df)\n",
    "    elif actions[\"verb\"] == \"list\" and actions[\"shapes\"] == 'row':\n",
    "        list_rows(df)\n",
    "    elif actions[\"verb\"] == \"post\" and actions[\"shapes\"] == 'cell':\n",
    "        post_cell(df, actions[\"var\"][0], actions[\"var\"][1], actions[\"var\"][2])\n",
    "    elif actions[\"verb\"] == \"get\" and actions[\"shapes\"] == 'unique_col':\n",
    "        get_unique_col(df, actions[\"var\"][0])\n",
    "    elif actions[\"verb\"] == \"get\" and actions[\"shapes\"] == 'perc_missing':\n",
    "        get_perc_missing(df)\n",
    "    elif actions[\"verb\"] == \"eminem\":\n",
    "        eminem()\n",
    "    else:\n",
    "        print(\"Not a valid command (enter 'help' for a list of commands)\")\n",
    "\n",
    "# Note: loadcsv ../data/imdb_over10k_votes_movies.csv \n",
    "#       will work if your data is in a sibling folder called 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e9aa0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['a','bb','ccc']\n",
    "numbers = [1,2,3]\n",
    "\n",
    "min(numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fsd22env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "72ab57b0b5f2fd64aef2c7b60b3862b1a450b7cb33941b7430bf767e797b1ae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
